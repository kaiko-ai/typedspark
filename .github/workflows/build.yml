name: Python package

on: [pull_request]

jobs:
  build:
    runs-on: ubuntu-latest
    container:
      image: bitnami/spark:3.5.3
      options: --user root
    timeout-minutes: 20
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12", "3.13"]

    steps:
      - uses: actions/checkout@v5

      # Required so setup-python's CPython can actually run inside this minimal image
      - name: Install CPython runtime deps
        run: |
          apt-get update
          apt-get install -y --no-install-recommends \
            lsb-release ca-certificates curl xz-utils tar \
            libgcc-s1 libstdc++6 libc6 \
            libssl3 libbz2-1.0 libsqlite3-0 libffi8 zlib1g \
            libncursesw6 libreadline8 liblzma5 libgdbm6 libnss3 libuuid1
          rm -rf /var/lib/apt/lists/*

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Linting
        run: |
          flake8
          pylint typedspark
          mypy .
          pyright .
          bandit typedspark/**/*.py
          black --check .
          isort --check .
          docformatter --black -c **/*.py

      - name: Testing
        run: |
          # we run this test seperately, to ensure that it is run without an active Spark session
          python -m pytest -m no_spark_session
          coverage run -m pytest
          coverage report -m --fail-under 100

      - name: Run notebooks
        run: |
          for FILE in docs/*/*.ipynb; do
            BASE=$(basename $FILE)
            cp $FILE .
            jupyter nbconvert --to notebook $BASE --execute
          done
