{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b83251c2",
   "metadata": {
    "papermill": {
     "duration": 0.003042,
     "end_time": "2023-04-13T15:19:55.870019",
     "exception": false,
     "start_time": "2023-04-13T15:19:55.866977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Advanced type-checking using linters\n",
    "## Functions that do not affect the schema\n",
    "\n",
    "There are a number of functions in `DataSet` which do not affect the schema. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf75d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T15:19:55.875316Z",
     "iopub.status.busy": "2023-04-13T15:19:55.875080Z",
     "iopub.status.idle": "2023-04-13T15:20:02.373741Z",
     "shell.execute_reply": "2023-04-13T15:20:02.373259Z"
    },
    "papermill": {
     "duration": 6.502752,
     "end_time": "2023-04-13T15:20:02.375098",
     "exception": false,
     "start_time": "2023-04-13T15:19:55.872346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.Builder().getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84b26e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T15:20:02.378689Z",
     "iopub.status.busy": "2023-04-13T15:20:02.378496Z",
     "iopub.status.idle": "2023-04-13T15:20:03.639073Z",
     "shell.execute_reply": "2023-04-13T15:20:03.638703Z"
    },
    "papermill": {
     "duration": 1.263607,
     "end_time": "2023-04-13T15:20:03.640269",
     "exception": false,
     "start_time": "2023-04-13T15:20:02.376662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typedspark import Column, Schema, DataSet, create_partially_filled_dataset\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "class A(Schema):\n",
    "    a: Column[StringType]\n",
    "\n",
    "df = create_partially_filled_dataset(spark, A, {A.a: [\"a\", \"b\", \"c\"]})\n",
    "res = df.filter(A.a == \"a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01675118",
   "metadata": {
    "papermill": {
     "duration": 0.001204,
     "end_time": "2023-04-13T15:20:03.643083",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.641879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the above example, `filter()` will not actually make any changes to the schema, hence we have implemented the return type of `DataSet.filter()` to be a `DataSet` of the same `Schema` that you started with. In other words, a linter will see that `res` is of the type `DataSet[A]`.\n",
    "\n",
    "This allows you to skip casting steps in many cases and instead define functions as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fe9344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T15:20:03.646707Z",
     "iopub.status.busy": "2023-04-13T15:20:03.646527Z",
     "iopub.status.idle": "2023-04-13T15:20:03.649004Z",
     "shell.execute_reply": "2023-04-13T15:20:03.648529Z"
    },
    "papermill": {
     "duration": 0.005816,
     "end_time": "2023-04-13T15:20:03.650274",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.644458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foo(df: DataSet[A]) -> DataSet[A]:\n",
    "    return df.filter(A.a == \"a\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed27a7d",
   "metadata": {
    "papermill": {
     "duration": 0.00118,
     "end_time": "2023-04-13T15:20:03.652922",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.651742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The functions for which this is currently implemented include:\n",
    "\n",
    "* `filter()`\n",
    "* `distinct()`\n",
    "* `orderBy()`\n",
    "\n",
    "## Functions applied to two DataSets of the same schema\n",
    "\n",
    "Similarly, some functions return a `DataSet[A]` when they take two `DataSet[A]` as an input. For example, here a linter will see that `res` is of the type `DataSet[A]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abfb0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T15:20:03.656004Z",
     "iopub.status.busy": "2023-04-13T15:20:03.655859Z",
     "iopub.status.idle": "2023-04-13T15:20:03.707767Z",
     "shell.execute_reply": "2023-04-13T15:20:03.707399Z"
    },
    "papermill": {
     "duration": 0.054827,
     "end_time": "2023-04-13T15:20:03.708927",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.654100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_a = create_partially_filled_dataset(spark, A, {A.a: [\"a\", \"b\", \"c\"]})\n",
    "df_b = create_partially_filled_dataset(spark, A, {A.a: [\"d\", \"e\", \"f\"]})\n",
    "\n",
    "res = df_a.unionByName(df_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa33e61",
   "metadata": {
    "papermill": {
     "duration": 0.00108,
     "end_time": "2023-04-13T15:20:03.711359",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.710279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The functions in this category include:\n",
    "\n",
    "* `unionByName()`\n",
    "* `join(..., how=\"semi\")`\n",
    "\n",
    "## Transformations\n",
    "\n",
    "Finally, the `transform()` function can also be typed. In the following example, a linter will see that `res` is of the type `DataSet[B]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0df362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T15:20:03.714917Z",
     "iopub.status.busy": "2023-04-13T15:20:03.714796Z",
     "iopub.status.idle": "2023-04-13T15:20:03.747490Z",
     "shell.execute_reply": "2023-04-13T15:20:03.747198Z"
    },
    "papermill": {
     "duration": 0.03619,
     "end_time": "2023-04-13T15:20:03.748613",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.712423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typedspark import transform_to_schema\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "class B(A):\n",
    "    b: Column[StringType]\n",
    "\n",
    "def foo(df: DataSet[A]) -> DataSet[A]:\n",
    "    return transform_to_schema(\n",
    "        df,\n",
    "        B,\n",
    "        {\n",
    "            B.b: lit(\"hi\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "res = (\n",
    "    create_partially_filled_dataset(spark, A, {A.a: [\"a\", \"b\", \"c\"]})\n",
    "    .transform(foo)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4221be22",
   "metadata": {
    "papermill": {
     "duration": 0.00112,
     "end_time": "2023-04-13T15:20:03.751179",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.750059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Did we miss anything?\n",
    "\n",
    "There are likely more functions that we did not yet cover. Feel free to make an issue and reach out when you find one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ad841",
   "metadata": {
    "papermill": {
     "duration": 0.001314,
     "end_time": "2023-04-13T15:20:03.753581",
     "exception": false,
     "start_time": "2023-04-13T15:20:03.752267",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "typedspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.404374,
   "end_time": "2023-04-13T15:20:04.375908",
   "environment_variables": {},
   "exception": null,
   "input_path": "docs/source/advanced_linting_support.ipynb",
   "output_path": "docs/source/advanced_linting_support.ipynb",
   "parameters": {},
   "start_time": "2023-04-13T15:19:54.971534",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
